{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "name": "RL_01_01_Gridworld(DQN).ipynb",
      "authorship_tag": "ABX9TyNkeNkdJFKNW1478o6Hf1Qr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juhumkwon/DeepLearning/blob/main/RL_01_01_Gridworld(DQN).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P84QaNFrtZ5N",
        "outputId": "a73754c7-2d88-42af-f6e6-7af46e381732"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opencv-python\n",
            "  Downloading opencv_python-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (19 kB)\n",
            "Requirement already satisfied: numpy<2.3.0,>=2 in /usr/local/lib/python3.12/dist-packages (from opencv-python) (2.0.2)\n",
            "Downloading opencv_python-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (67.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m67.0/67.0 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: opencv-python\n",
            "Successfully installed opencv-python-4.12.0.88\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Collecting astunparse>=1.6.0 (from tensorflow)\n",
            "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
            "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Collecting google_pasta>=0.1.1 (from tensorflow)\n",
            "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
            "Collecting libclang>=13.0.0 (from tensorflow)\n",
            "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: opt_einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf>=5.28.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (6.32.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing_extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.14.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.74.0)\n",
            "Collecting tensorboard~=2.20.0 (from tensorflow)\n",
            "  Downloading tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: keras>=3.10.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n",
            "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow)\n",
            "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.10.0->tensorflow) (14.1.0)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.10.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/lib/python3/dist-packages (from tensorboard~=2.20.0->tensorflow) (3.3.6)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.20.0->tensorflow) (11.3.0)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.20.0->tensorflow)\n",
            "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting werkzeug>=1.0.1 (from tensorboard~=2.20.0->tensorflow)\n",
            "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n",
            "Downloading tensorflow-2.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (620.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m620.7/620.7 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
            "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
            "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m82.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m114.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m122.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: libclang, flatbuffers, wheel, werkzeug, tensorboard-data-server, google_pasta, tensorboard, astunparse, tensorflow\n",
            "Successfully installed astunparse-1.6.3 flatbuffers-25.2.10 google_pasta-0.2.0 libclang-18.1.1 tensorboard-2.20.0 tensorboard-data-server-0.7.2 tensorflow-2.20.0 werkzeug-3.1.3 wheel-0.45.1\n"
          ]
        }
      ],
      "source": [
        "!pip install opencv-python\n",
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import random\n",
        "import cv2\n",
        "import time\n",
        "from google.colab.patches import cv2_imshow\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# GridWorld í™˜ê²½\n",
        "class GridWorld:\n",
        "    def __init__(self, size=5):\n",
        "        self.size = size\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.agent_pos = [0, 0]\n",
        "        self.goal_pos = [self.size - 1, self.size - 1]\n",
        "        return self.get_state()\n",
        "\n",
        "    def get_state(self):\n",
        "        return self.agent_pos[0] * self.size + self.agent_pos[1]\n",
        "\n",
        "    def step(self, action):\n",
        "        if action == 0 and self.agent_pos[0] > 0:\n",
        "            self.agent_pos[0] -= 1   # ìœ„ë¡œ ì´ë™ â†’ í–‰(row) ê°ì†Œ\n",
        "        elif action == 1 and self.agent_pos[0] < self.size - 1:\n",
        "            self.agent_pos[0] += 1   # ì•„ë˜ë¡œ ì´ë™ â†’ í–‰(row) ì¦ê°€\n",
        "        elif action == 2 and self.agent_pos[1] > 0:\n",
        "            self.agent_pos[1] -= 1    # ì™¼ìª½ ì´ë™ â†’ ì—´(col) ê°ì†Œ\n",
        "        elif action == 3 and self.agent_pos[1] < self.size - 1:\n",
        "            self.agent_pos[1] += 1     # ì˜¤ë¥¸ìª½ ì´ë™ â†’ ì—´(col) ì¦ê°€\n",
        "\n",
        "        done = self.agent_pos == self.goal_pos\n",
        "        reward = 1.0 if done else -0.01\n",
        "        return self.get_state(), reward, done\n",
        "\n",
        "    def render(self, delay=200):\n",
        "        clear_output(wait=True)  # ì¶œë ¥ ëˆ„ì  ë°©ì§€\n",
        "        cell_size = 70\n",
        "        img = np.ones((self.size * cell_size, self.size * cell_size, 3), dtype=np.uint8) * 255\n",
        "\n",
        "        # ê²©ì ê·¸ë¦¬ê¸°\n",
        "        for i in range(self.size):\n",
        "            for j in range(self.size):\n",
        "                x, y = j * cell_size, i * cell_size\n",
        "                cv2.rectangle(img, (x, y), (x + cell_size, y + cell_size), (200, 200, 200), 1)\n",
        "\n",
        "        # ì—ì´ì „íŠ¸: íŒŒë‘\n",
        "        ax, ay = self.agent_pos[1] * cell_size, self.agent_pos[0] * cell_size\n",
        "        cv2.rectangle(img, (ax, ay), (ax + cell_size, ay + cell_size), (255, 0, 0), -1)\n",
        "\n",
        "        # ëª©í‘œ: ì´ˆë¡\n",
        "        gx, gy = self.goal_pos[1] * cell_size, self.goal_pos[0] * cell_size\n",
        "        cv2.rectangle(img, (gx, gy), (gx + cell_size, gy + cell_size), (0, 255, 0), -1)\n",
        "\n",
        "        cv2_imshow(img)\n",
        "        time.sleep(delay / 1000.0)\n",
        "\n",
        "# Q-network\n",
        "class QNet(tf.keras.Model):\n",
        "    def __init__(self, state_size, action_size):\n",
        "        super(QNet, self).__init__()\n",
        "        self.d1 = tf.keras.layers.Dense(32, activation='relu', input_shape=(state_size,))\n",
        "        self.d2 = tf.keras.layers.Dense(32, activation='relu')\n",
        "        self.out = tf.keras.layers.Dense(action_size, activation='linear')\n",
        "\n",
        "    \"\"\"\n",
        "    TensorFlowì˜ ì„œë¸Œí´ë˜ì‹± ëª¨ë¸ (tf.keras.Model ìƒì†) ë°©ì‹ì—ì„œëŠ”\n",
        "    ëª¨ë¸ì´ ì–´ë–»ê²Œ forward passë¥¼ ì²˜ë¦¬í• ì§€ë¥¼ ì§ì ‘ call()ì—ì„œ ì •ì˜í•´ì•¼ í•©ë‹ˆë‹¤.\n",
        "    cf.)\n",
        "    Sequential ë˜ëŠ” Functional API\tâŒ í•„ìš” ì—†ìŒ (ë ˆì´ì–´ ìˆœì„œ ìë™ ì²˜ë¦¬)\n",
        "    Subclassing API (class QNet(tf.keras.Model))\tâœ… ê¼­ í•„ìš”\n",
        "    \"\"\"\n",
        "    def call(self, x):\n",
        "        x = self.d1(x)\n",
        "        x = self.d2(x)\n",
        "        return self.out(x)\n",
        "\n",
        "# í•˜ì´í¼íŒŒë¼ë¯¸í„°\n",
        "grid_size = 5\n",
        "state_size = grid_size * grid_size\n",
        "action_size = 4\n",
        "episodes = 300\n",
        "\n",
        "gamma = 0.99\n",
        "epsilon = 1.0\n",
        "epsilon_decay = 0.995\n",
        "epsilon_min = 0.1\n",
        "learning_rate = 0.01\n",
        "\n",
        "env = GridWorld(grid_size)\n",
        "model = QNet(state_size, action_size)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate), loss='mse')\n",
        "\n",
        "# í•™ìŠµ ë£¨í”„\n",
        "for episode in range(episodes):\n",
        "    state = env.reset()\n",
        "    done = False\n",
        "    total_reward = 0\n",
        "\n",
        "    while not done:\n",
        "        state_input = tf.one_hot(state, state_size)\n",
        "        state_input = tf.reshape(state_input, [1, state_size])\n",
        "\n",
        "        if np.random.rand() < epsilon:\n",
        "            action = np.random.choice(action_size)\n",
        "        else:\n",
        "            q_values = model.predict(state_input, verbose=0)\n",
        "            action = np.argmax(q_values[0])\n",
        "\n",
        "        next_state, reward, done = env.step(action)\n",
        "        next_state_input = tf.one_hot(next_state, state_size)\n",
        "        next_state_input = tf.reshape(next_state_input, [1, state_size])\n",
        "\n",
        "        target_q = model.predict(state_input, verbose=0)\n",
        "        if done:\n",
        "            target_q[0][action] = reward\n",
        "        else:\n",
        "            next_q = model.predict(next_state_input, verbose=0)\n",
        "            target_q[0][action] = reward + gamma * np.max(next_q[0])\n",
        "\n",
        "        model.fit(state_input, target_q, epochs=1, verbose=0)\n",
        "\n",
        "        state = next_state\n",
        "        total_reward += reward\n",
        "\n",
        "        env.render()  # âœ… ì¶œë ¥ë³´ë‹¤ ë¨¼ì € ìœ„ì¹˜í•´ì•¼ printê°€ ë³´ì„\n",
        "\n",
        "    if epsilon > epsilon_min:\n",
        "        epsilon *= epsilon_decay\n",
        "\n",
        "    # âœ… ëª©í‘œ ë„ë‹¬ ì‹œ print + 1ì´ˆ ëŒ€ê¸°\n",
        "    if reward == 1.0:\n",
        "        print(f\"âœ… Episode {episode+1}: Goal reached! Total reward = {total_reward:.2f}, Epsilon = {epsilon:.3f}\")\n",
        "        time.sleep(3)  # 1ì´ˆ ì •ì§€"
      ],
      "metadata": {
        "id": "u33x71bVtkeD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "í”„ë¡œê·¸ë¨ ì„¤ëª…\n",
        "\n",
        "\n",
        "1. ì—ì´ì „íŠ¸ ìœ„ì¹˜\n",
        "\n",
        "def get_state(self):\n",
        "    return self.agent_pos[0] * self.size + self.agent_pos[1]\n",
        "\n",
        "self.agent_pos : ì—ì´ì „íŠ¸ì˜ í˜„ì¬ ìœ„ì¹˜. ì¼ë°˜ì ìœ¼ë¡œ [row, col] í˜•íƒœì˜ ì¢Œí‘œ.\n",
        "self.size : ê·¸ë¦¬ë“œ(í™˜ê²½)ì˜ ê°€ë¡œ í¬ê¸°(ì—´ì˜ ê°œìˆ˜).\n",
        "self.agent_pos[0] * self.size : í˜„ì¬ row(í–‰) * ì—´ì˜ ê°œìˆ˜ â†’ ê·¸ í–‰ì´ ì‹œì‘ë˜ëŠ” 1ì°¨ì› ì¸ë±ìŠ¤ ìœ„ì¹˜.\n",
        "+ self.agent_pos[1] : ê·¸ í–‰ ì•ˆì—ì„œì˜ col(ì—´) ìœ„ì¹˜ë¥¼ ë”í•´ì¤Œ.\n",
        "ì¦‰, (row, col) â†’ row * size + col ë¡œ ë§¤í•‘í•˜ëŠ” ê²ƒ.\n",
        "\n",
        "ì˜ˆì‹œ\n",
        "ë§Œì•½ self.size = 5ì´ê³ ,\n",
        "self.agent_pos = [2, 3]ì´ë¼ë©´:\n",
        "state = 2 * 5 + 3 = 13\n",
        "\n",
        "ë§Œì•½ size = 4ì¸ GridWorld (4x4 ê²©ì)ê°€ ìˆë‹¤ë©´:\n",
        "(row, col)\tstate ê°’\n",
        "(0, 0)\t0\n",
        "(0, 1)\t1\n",
        "(0, 2)\t2\n",
        "(0, 3)\t3\n",
        "(1, 0)\t4\n",
        "(1, 1)\t5\n",
        "...\t...\n",
        "(3, 3)\t15\n",
        "\n",
        "ì´ë ‡ê²Œ ì „ì²´ state ê³µê°„ì€ 0 ~ size*size - 1 ë²”ìœ„ë¥¼ ê°€ì§‘ë‹ˆë‹¤.\n",
        "\n",
        "2. self.agent_posì˜ êµ¬ì¡°\n",
        "self.agent_pos = [row, col]\n",
        "ì´ë¼ê³  ì •ì˜í•˜ë©´,\n",
        "self.agent_pos[0] â†’ row (ì„¸ë¡œ ìœ„ì¹˜)\n",
        "self.agent_pos[1] â†’ col (ê°€ë¡œ ìœ„ì¹˜)\n",
        "\n",
        "(0,0) (0,1) (0,2) (0,3)\n",
        "(1,0) (1,1) (1,2) (1,3)\n",
        "(2,0) (2,1) (2,2) (2,3)\n",
        "(3,0) (3,1) (3,2) (3,3)\n",
        "\n",
        "ì²« ë²ˆì§¸ ê°’(row)ì€ ì•„ë˜ë¡œ ë‚´ë ¤ê°ˆìˆ˜ë¡ ì¦ê°€\n",
        "ë‘ ë²ˆì§¸ ê°’(col)ì€ ì˜¤ë¥¸ìª½ìœ¼ë¡œ ê°ˆìˆ˜ë¡ ì¦ê°€\n",
        "ì¦‰, (row, col) ì²´ê³„ëŠ” ìˆ˜í•™ ì¢Œí‘œê³„ (x, y)ì™€ ë°˜ëŒ€ ëŠë‚Œì´ì§€ë§Œ, í–‰ë ¬ ì¸ë±ìŠ¤ ê´€ë¡€ì— ë§ì¶˜ ê²ë‹ˆë‹¤.\n",
        "\n",
        "3. One-hot ì¸ì½”ë”©\n",
        "state_input = tf.one_hot(state, state_size)\n",
        "\n",
        "state_size = 25 (5x5 ê·¸ë¦¬ë“œ)\n",
        "state = 13 ì´ë¼ë©´\n",
        "state_input = [0, 0, 0, ..., 1, ..., 0]   # ê¸¸ì´ 25, 13ë²ˆì§¸ê°€ 1\n",
        "stateëŠ” ê·¸ëƒ¥ ì •ìˆ˜ í•˜ë‚˜(ì˜ˆ: 13)ë¼ì„œ, ì‹ ê²½ë§ì€ ì´ë¥¼ í•™ìŠµí•˜ê¸° ì–´ë ¤ì›€\n",
        "One-hot ì¸ì½”ë”©ì„ í†µí•´ ëª¨ë“  ìƒíƒœë¥¼ ê³ ìœ í•œ ë²¡í„° í‘œí˜„ìœ¼ë¡œ ë§Œë“¤ì–´ ì¤Œ\n",
        "ì´ ë°©ì‹ì€ íƒ­í˜•(state ê°œìˆ˜ê°€ ì‘ì„ ë•Œ) ìœ ìš©\n",
        "\n",
        "4. np.random.choice í•¨ìˆ˜\n",
        "\n",
        "np.random.choice(a, size=None, replace=True, p=None) ëŠ”\n",
        "a : ì„ íƒí•  ëŒ€ìƒ(ì •ìˆ˜ ë˜ëŠ” ë°°ì—´)\n",
        "size : ëª‡ ê°œë¥¼ ë½‘ì„ì§€\n",
        "replace : ì¤‘ë³µ í—ˆìš© ì—¬ë¶€\n",
        "p : ê° ëŒ€ìƒì´ ì„ íƒë  í™•ë¥ \n",
        "\n",
        "np.random.choice(3)  # 0, 1, 2 ì¤‘ í•˜ë‚˜ë¥¼ ëœë¤ ì„ íƒ\n",
        "np.random.choice(3, p=[0.1, 0.2, 0.7])  # í™•ë¥ ì— ë”°ë¼ ì„ íƒ\n",
        "\n",
        "5. ì´ í”„ë¡œê·¸ë¨(DQNë¥˜)ì—ì„œëŠ” ì™œ predict â†’ fit êµ¬ì¡°ì¼ê¹Œ?\n",
        "ê°•í™”í•™ìŠµì€ ì§€ë„í•™ìŠµê³¼ ë‹¬ë¦¬ â€œì •ë‹µ ë ˆì´ë¸”(y)â€ì´ ì£¼ì–´ì§€ì§€ ì•Šì•„ìš”.\n",
        "ì—ì´ì „íŠ¸ê°€ í™˜ê²½ì„ íƒí—˜í•˜ë©´ì„œ ì–»ì€ ë³´ìƒê³¼ ë‹¤ìŒ ìƒíƒœë¥¼ ê¸°ë°˜ìœ¼ë¡œ, ìì²´ì ìœ¼ë¡œ í•™ìŠµí•  targetì„ ë§Œë“¤ì–´ì•¼ í•©ë‹ˆë‹¤.\n",
        "\n",
        "ğŸ”¹ ê°•í™”í•™ìŠµì—ì„œì˜ íë¦„\n",
        "\n",
        "predict()\n",
        "- í˜„ì¬ ìƒíƒœ sì—ì„œ Q(s, :) (ëª¨ë“  í–‰ë™ì˜ Qê°’)ì„ ì¶”ì •\n",
        "- ì´ ì¤‘ ì„ íƒí•œ actionì— ëŒ€í•´ ì—…ë°ì´íŠ¸í•  ë¶€ë¶„ì„ ì°¾ìŒ\n",
        "\n",
        "[target_q ìƒì„±]\n",
        "ë²¨ë§Œ ë°©ì •ì‹ìœ¼ë¡œ ê³„ì‚°ëœ ìƒˆë¡œìš´ Qê°’(reward or reward + Î³ * max Q(sâ€², aâ€²))ì„\n",
        "target_q[0][action]ì— ë°˜ì˜\n",
        "ë‚˜ë¨¸ì§€ í–‰ë™ì˜ Qê°’ì€ predictì—ì„œ ê°€ì ¸ì˜¨ ê°’ ìœ ì§€ (ì•ˆ í•œ í–‰ë™ê¹Œì§€ êµ³ì´ ìˆ˜ì •í•˜ì§€ ì•ŠìŒ)\n",
        "\n",
        "fit()\n",
        "\n",
        "- ì…ë ¥: í˜„ì¬ ìƒíƒœ(state)\n",
        "- ì •ë‹µ: ìš°ë¦¬ê°€ ë§Œë“  target_q\n",
        "- ëª¨ë¸ì´ ì˜ˆì¸¡í•œ Q(s, :)ì™€ ìš°ë¦¬ê°€ ë§Œë“  íƒ€ê¹ƒ ë²¡í„°ê°€ ê°€ê¹Œì›Œì§€ë„ë¡ í•™ìŠµ\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "x0rNuWEGrVUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**êµµì€ í…ìŠ¤íŠ¸**"
      ],
      "metadata": {
        "id": "Rz5pPrBMtfnl"
      }
    }
  ]
}