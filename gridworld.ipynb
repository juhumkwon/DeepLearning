{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "authorship_tag": "ABX9TyMl723Fu+rKOcGwtj/VgjY5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juhumkwon/DeepLearning/blob/main/gridworld.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "P84QaNFrtZ5N",
        "outputId": "8df8da67-5edc-4ef1-e4e8-11c5ac5c7967"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opencv-python\n",
            "  Downloading opencv_python-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (19 kB)\n",
            "Requirement already satisfied: numpy<2.3.0,>=2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (2.0.2)\n",
            "Downloading opencv_python-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (67.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: opencv-python\n",
            "Successfully installed opencv-python-4.12.0.88\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Collecting astunparse>=1.6.0 (from tensorflow)\n",
            "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
            "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
            "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
            "Collecting libclang>=13.0.0 (from tensorflow)\n",
            "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.0)\n",
            "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 (from tensorflow)\n",
            "  Downloading protobuf-5.29.5-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.14.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.73.1)\n",
            "Collecting tensorboard~=2.19.0 (from tensorflow)\n",
            "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.5.1)\n",
            "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
            "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow)\n",
            "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (14.0.0)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.7.14)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/lib/python3/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.3.6)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.19.0->tensorflow)\n",
            "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting werkzeug>=1.0.1 (from tensorboard~=2.19.0->tensorflow)\n",
            "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Downloading tensorflow-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (644.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m644.9/644.9 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
            "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
            "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m84.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-5.29.5-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.9/319.9 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m122.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m118.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m113.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: libclang, flatbuffers, wheel, werkzeug, tensorflow-io-gcs-filesystem, tensorboard-data-server, protobuf, google-pasta, tensorboard, astunparse, tensorflow\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 6.31.1\n",
            "    Uninstalling protobuf-6.31.1:\n",
            "      Successfully uninstalled protobuf-6.31.1\n",
            "Successfully installed astunparse-1.6.3 flatbuffers-25.2.10 google-pasta-0.2.0 libclang-18.1.1 protobuf-5.29.5 tensorboard-2.19.0 tensorboard-data-server-0.7.2 tensorflow-2.19.0 tensorflow-io-gcs-filesystem-0.37.1 werkzeug-3.1.3 wheel-0.45.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "3a6193aa02b34ba3a0c93c6eb7d9aa8e"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install opencv-python\n",
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import random\n",
        "import cv2\n",
        "import time\n",
        "from google.colab.patches import cv2_imshow\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# GridWorld 환경\n",
        "class GridWorld:\n",
        "    def __init__(self, size=5):\n",
        "        self.size = size\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.agent_pos = [0, 0]\n",
        "        self.goal_pos = [self.size - 1, self.size - 1]\n",
        "        return self.get_state()\n",
        "\n",
        "    def get_state(self):\n",
        "        return self.agent_pos[0] * self.size + self.agent_pos[1]\n",
        "\n",
        "    def step(self, action):\n",
        "        if action == 0 and self.agent_pos[0] > 0:\n",
        "            self.agent_pos[0] -= 1\n",
        "        elif action == 1 and self.agent_pos[0] < self.size - 1:\n",
        "            self.agent_pos[0] += 1\n",
        "        elif action == 2 and self.agent_pos[1] > 0:\n",
        "            self.agent_pos[1] -= 1\n",
        "        elif action == 3 and self.agent_pos[1] < self.size - 1:\n",
        "            self.agent_pos[1] += 1\n",
        "\n",
        "        done = self.agent_pos == self.goal_pos\n",
        "        reward = 1.0 if done else -0.01\n",
        "        return self.get_state(), reward, done\n",
        "\n",
        "    def render(self, delay=200):\n",
        "        clear_output(wait=True)  # 출력 누적 방지\n",
        "        cell_size = 70\n",
        "        img = np.ones((self.size * cell_size, self.size * cell_size, 3), dtype=np.uint8) * 255\n",
        "\n",
        "        # 격자 그리기\n",
        "        for i in range(self.size):\n",
        "            for j in range(self.size):\n",
        "                x, y = j * cell_size, i * cell_size\n",
        "                cv2.rectangle(img, (x, y), (x + cell_size, y + cell_size), (200, 200, 200), 1)\n",
        "\n",
        "        # 에이전트: 파랑\n",
        "        ax, ay = self.agent_pos[1] * cell_size, self.agent_pos[0] * cell_size\n",
        "        cv2.rectangle(img, (ax, ay), (ax + cell_size, ay + cell_size), (255, 0, 0), -1)\n",
        "\n",
        "        # 목표: 초록\n",
        "        gx, gy = self.goal_pos[1] * cell_size, self.goal_pos[0] * cell_size\n",
        "        cv2.rectangle(img, (gx, gy), (gx + cell_size, gy + cell_size), (0, 255, 0), -1)\n",
        "\n",
        "        cv2_imshow(img)\n",
        "        time.sleep(delay / 1000.0)\n",
        "\n",
        "# Q-network\n",
        "class QNet(tf.keras.Model):\n",
        "    def __init__(self, state_size, action_size):\n",
        "        super(QNet, self).__init__()\n",
        "        self.d1 = tf.keras.layers.Dense(32, activation='relu', input_shape=(state_size,))\n",
        "        self.d2 = tf.keras.layers.Dense(32, activation='relu')\n",
        "        self.out = tf.keras.layers.Dense(action_size, activation='linear')\n",
        "\n",
        "    \"\"\"\n",
        "    TensorFlow의 서브클래싱 모델 (tf.keras.Model 상속) 방식에서는\n",
        "    모델이 어떻게 forward pass를 처리할지를 직접 call()에서 정의해야 합니다.\n",
        "    cf.)\n",
        "    Sequential 또는 Functional API\t❌ 필요 없음 (레이어 순서 자동 처리)\n",
        "    Subclassing API (class QNet(tf.keras.Model))\t✅ 꼭 필요\n",
        "    \"\"\"\n",
        "    def call(self, x):\n",
        "        x = self.d1(x)\n",
        "        x = self.d2(x)\n",
        "        return self.out(x)\n",
        "\n",
        "# 하이퍼파라미터\n",
        "grid_size = 5\n",
        "state_size = grid_size * grid_size\n",
        "action_size = 4\n",
        "episodes = 300\n",
        "\n",
        "gamma = 0.99\n",
        "epsilon = 1.0\n",
        "epsilon_decay = 0.995\n",
        "epsilon_min = 0.1\n",
        "learning_rate = 0.01\n",
        "\n",
        "env = GridWorld(grid_size)\n",
        "model = QNet(state_size, action_size)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate), loss='mse')\n",
        "\n",
        "# 학습 루프\n",
        "for episode in range(episodes):\n",
        "    state = env.reset()\n",
        "    done = False\n",
        "    total_reward = 0\n",
        "\n",
        "    while not done:\n",
        "        state_input = tf.one_hot(state, state_size)\n",
        "        state_input = tf.reshape(state_input, [1, state_size])\n",
        "\n",
        "        if np.random.rand() < epsilon:\n",
        "            action = np.random.choice(action_size)\n",
        "        else:\n",
        "            q_values = model.predict(state_input, verbose=0)\n",
        "            action = np.argmax(q_values[0])\n",
        "\n",
        "        next_state, reward, done = env.step(action)\n",
        "        next_state_input = tf.one_hot(next_state, state_size)\n",
        "        next_state_input = tf.reshape(next_state_input, [1, state_size])\n",
        "\n",
        "        target_q = model.predict(state_input, verbose=0)\n",
        "        if done:\n",
        "            target_q[0][action] = reward\n",
        "        else:\n",
        "            next_q = model.predict(next_state_input, verbose=0)\n",
        "            target_q[0][action] = reward + gamma * np.max(next_q[0])\n",
        "\n",
        "        model.fit(state_input, target_q, epochs=1, verbose=0)\n",
        "\n",
        "        state = next_state\n",
        "        total_reward += reward\n",
        "\n",
        "        env.render()  # ✅ 출력보다 먼저 위치해야 print가 보임\n",
        "\n",
        "    if epsilon > epsilon_min:\n",
        "        epsilon *= epsilon_decay\n",
        "\n",
        "    # ✅ 목표 도달 시 print + 1초 대기\n",
        "    if reward == 1.0:\n",
        "        print(f\"✅ Episode {episode+1}: Goal reached! Total reward = {total_reward:.2f}, Epsilon = {epsilon:.3f}\")\n",
        "        time.sleep(3)  # 1초 정지"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        },
        "id": "u33x71bVtkeD",
        "outputId": "c751e3f7-1133-4dd7-d3b9-bfaebcee4b02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=350x350>"
            ],
            "image/png": "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\n",
            "image/jpeg": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2-606767965.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mnext_state_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_state_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mtarget_q\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0mtarget_q\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[1;32m    557\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 559\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    560\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_epoch_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcontextlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontextmanager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py\u001b[0m in \u001b[0;36m_enumerate_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_iterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_seen\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_seen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m       raise RuntimeError(\"`tf.data.Dataset` only supports Python-style \"\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[1;32m    707\u001b[0m             \u001b[0;34m\"When `dataset` is provided, `element_spec` and `components` must \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m             \"not be specified.\")\n\u001b[0;32m--> 709\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_next_call_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    746\u001b[0m             self._flat_output_types)\n\u001b[1;32m    747\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_set_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfulltype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m       \u001b[0mgen_dataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_variant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    749\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36mmake_iterator\u001b[0;34m(dataset, iterator, name)\u001b[0m\n\u001b[1;32m   3476\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3477\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3478\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   3479\u001b[0m         _ctx, \"MakeIterator\", name, dataset, iterator)\n\u001b[1;32m   3480\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}